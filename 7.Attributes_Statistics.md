# Attribute Statistics属性统计

## CATALOG

1. [Attribute Statistics属性统计](#attribute-statistics属性统计)
   1. [CATALOG](#catalog)
   2. [Norm范数](#norm范数)
      1. [数据准备1](#数据准备1)
      2. [求norm范数](#求norm范数)
   3. [一般属性](#一般属性)
      1. [数据准备2](#数据准备2)
      2. [使用示范](#使用示范)
   4. [进阶操作](#进阶操作)
      1. [数据准备3](#数据准备3)

## Norm范数

- 在PyTorch中，范数（Norm）是数学上的一个概念，用于衡量向量、矩阵或更高阶张量（Tensor）的“大小”或“长度”。在向量空间中，范数是一个将向量映射到非负实数的函数，且满足特定的性质，如非负性、齐次性和三角不等式。

### 数据准备1

```Python
a = torch.full([8],1.)
b = a.view(2,4)
c = a.view(2,2,2)
b
Out[13]: 
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.]])
c
Out[14]: 
tensor([[[1., 1.],
         [1., 1.]],
        [[1., 1.],
         [1., 1.]]])
# 注意要使用浮点数，否则求范数将会报错
```

### 求norm范数

- 使用`norm(i)`求范数

范数类型：

1. L1范数（1-范数）：向量中各个元素绝对值之和。在PyTorch中，可以通过将p参数设置为1来计算。
2. L2范数（2-范数或欧几里得范数）：向量各元素平方和的平方根。在PyTorch中，这是p=2时的默认情况，也是最常见的范数之一。
  
```Python
a.norm(1),b.norm(1),c.norm(1)
Out[15]: (tensor(8.), tensor(8.), tensor(8.))
# L1范数

a.norm(2),b.norm(2),c.norm(2)
Out[16]: (tensor(2.8284), tensor(2.8284), tensor(2.8284))
# L2范数
```

- 求指定维度的范数`norm(i,dim = j)`

```Python
b.norm(1,dim = 1)
Out[17]: tensor([4., 4.])
# 维度为1的L1范数

b.norm(2,dim = 1)
Out[18]: tensor([2., 2.])
# 维度为1的L2范数

c.norm(1,dim = 1)
Out[19]: 
tensor([[2., 2.],
        [2., 2.]])
```

## 一般属性

一般属性包括：

1. 最小值`min()`
2. 最大值`max()`
3. 平均值`mean`
4. 乘积`prod()`
5. 求和`sum()`
6. 最大值索引`argmax()`
7. 最小值索引`argmin()`

### 数据准备2

```Python
a = torch.arange(8).view(2,4).float()
a
Out[21]: 
tensor([[0., 1., 2., 3.],
        [4., 5., 6., 7.]])
```

### 使用示范

```Python
a.min(),a.max(),a.mean(),a.prod()
Out[22]: (tensor(0.), tensor(7.), tensor(3.5000), tensor(0.))

a.sum()
Out[23]: tensor(28.)

a.argmax(),a.argmin()
Out[24]: (tensor(7), tensor(0))

a.argmax(dim = 1) # 指定维度
Out[25]: tensor([3, 3])
```

## 进阶操作

### 数据准备3

```Python
a = torch.randn(4,10)
```

- `max(dim = i,keepdim = True)`
- `keepdim = True`可以保持维度视图一致

```Python
a.max(dim = 1,keepdim = True)
Out[30]: 
torch.return_types.max(
values=tensor([[2.0904],
        [0.8125],
        [1.6967],
        [2.0314]]),
indices=tensor([[4],
        [1],
        [7],
        [1]]))
# 获得每一行的最大值和索引
```

- `topk(i,dim = j)`返回前k大的数据和索引

```Python
a.topk(2,dim = 1)
Out[31]: 
torch.return_types.topk(
values=tensor([[2.0904, 1.8129],
        [0.8125, 0.6773],
        [1.6967, 1.4155],
        [2.0314, 1.1019]]),
indices=tensor([[4, 5],
        [1, 6],
        [7, 8],
        [1, 7]]))
# 返回前2大的数据 第j维度

a.topk(2,dim = 1,largest = False)
Out[32]: 
torch.return_types.topk(
values=tensor([[-1.3614, -0.8890],
        [-1.5680, -1.5443],
        [-1.2478, -0.6732],
        [-1.5662, -1.5078]]),
indices=tensor([[6, 9],
        [5, 0],
        [0, 2],
        [5, 9]]))
# largest = False 从值小的数开始取
```

- `kthvalue()`返回从小到大第k的数字和索引

```Python
a.kthvalue(8,dim = 1)
Out[33]: 
torch.return_types.kthvalue(
values=tensor([1.7687, 0.0198, 0.8422, 0.2725]),
indices=tensor([3, 7, 1, 4]))
```

- 比对函数

1. 比较运算符`a > 0`
2. `gt()`,`eq()`,`equal()`

```Python
a = torch.ones(2,3)
b = torch.randn(2,3)

torch.eq(a,b) # 一个一个比较
Out[39]: 
tensor([[False, False, False],
        [False, False, False]])
torch.eq(a,a)
Out[40]: 
tensor([[True, True, True],
        [True, True, True]])

torch.equal(a,a) # 返回总体比较结果
Out[41]: True
```
